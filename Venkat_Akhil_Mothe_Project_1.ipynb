{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlLCK6UgrrpW"
   },
   "source": [
    "# Project 01 - Classify the 10 digits using MNIST data\n",
    "\n",
    "You are required to implement the convolutional neural network using purely numpy to classify the digits. All the techniques and codes will be covered in the next 2 weeks.\n",
    "\n",
    "## Due date\n",
    "\n",
    "March 31th, 2024\n",
    "\n",
    "## Tasks\n",
    "The project include two tasks:\n",
    "### 1. task one: Use the image data (vector) as input, and use Deep feed forward netork to train and predict the labels.\n",
    "### 2. task two: Reshape the image data to 2D array and use it as input, and use convolution neural network to train and predict the labels\n",
    "\n",
    "## Extra Credits\n",
    "If you want to speed up the training using GPU, you will need to write C++ code and wrap it using pybind11 and call it in your python code. This will give you 10 extra credits for this project.\n",
    "\n",
    "## Rubics\n",
    "1. If you code can run at my side and include the basic training cycle, you will get 40% of the total score;\n",
    "2. Your implementation of fully connected layers (forward and backpropagation pass) ----- 20%;\n",
    "3. Your implementation of Convolution layer (forward and backpropagation pass) ----- 20%\n",
    "4. Complete two tasks ----- 20%\n",
    "\n",
    "## Data Description\n",
    "[MNIST](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ohha6cR7ufYF"
   },
   "outputs": [],
   "source": [
    "# load the mnist data\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33464,
     "status": "ok",
     "timestamp": 1695215741025,
     "user": {
      "displayName": "Weizhe Li",
      "userId": "04517133090572802686"
     },
     "user_tz": 240
    },
    "id": "ChXaGZKCulwM",
    "outputId": "7ddf7663-3895-4e00-d6fd-40594bbb1280"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEKHYA\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist_28 = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rdg9fXJLvBJL"
   },
   "outputs": [],
   "source": [
    "mnist_28_img= mnist_28.data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1695215819357,
     "user": {
      "displayName": "Weizhe Li",
      "userId": "04517133090572802686"
     },
     "user_tz": 240
    },
    "id": "bX8G-CwQvHcE",
    "outputId": "7e1897a3-efc4-4f2c-8eaf-1187c4b686cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_28_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_28_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "smYgTNmovS5f"
   },
   "outputs": [],
   "source": [
    "#display one image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1695215964889,
     "user": {
      "displayName": "Weizhe Li",
      "userId": "04517133090572802686"
     },
     "user_tz": 240
    },
    "id": "Hw6NxBBJvajw",
    "outputId": "0366ed09-f96d-4d22-e053-05c41cc83938"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d44fd2bb50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaiElEQVR4nO3de2xT5/3H8Y+h4AJNLGWQ2BkhiirQpkJhXMpFlJtERLYiKN0EdCrhH0THRWVph8agI5smUqGCui2Dbd3GQIWBtFLKVFaaKSSwUaaUi4pYhUCEkYpkGRGzQ6BGwPP7A+FfTULgGJtv7Lxf0iPhc86X883hIZ88sX3sc845AQBgoId1AwCA7osQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJnHrBu4261bt3Tx4kVlZWXJ5/NZtwMA8Mg5p9bWVuXn56tHj87XOl0uhC5evKiCggLrNgAAD6mhoUEDBw7s9Jgu9+u4rKws6xYAAEnwIN/PUxZCmzZtUlFRkR5//HGNGjVKhw4deqA6fgUHAJnhQb6fpySEdu3apRUrVmj16tU6fvy4nn32WZWUlOjChQupOB0AIE35UnEX7bFjx2rkyJHavHlzbNvXv/51zZ49WxUVFZ3WRiIRBQKBZLcEAHjEwuGwsrOzOz0m6Suh69ev6+jRoyouLo7bXlxcrMOHD7c7PhqNKhKJxA0AQPeQ9BC6dOmSbt68qby8vLjteXl5ampqand8RUWFAoFAbPDKOADoPlL2woS7n5ByznX4JNWqVasUDodjo6GhIVUtAQC6mKS/T6h///7q2bNnu1VPc3Nzu9WRJPn9fvn9/mS3AQBIA0lfCfXu3VujRo1SVVVV3PaqqipNmDAh2acDAKSxlNwxoaysTC+99JJGjx6t8ePH67e//a0uXLigl19+ORWnAwCkqZSE0Ny5c9XS0qKf/vSnamxs1NChQ7Vv3z4VFham4nQAgDSVkvcJPQzeJwQAmcHkfUIAADwoQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYecy6AQAPZtSoUZ5rli1bltC5FixY4Llm27Ztnmt++ctfeq45duyY5xp0XayEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmPE555x1E18WiUQUCASs2wBSasSIEZ5rqqurPddkZ2d7rnmUwuGw55qvfOUrKegEqRAOh+87B1kJAQDMEEIAADNJD6Hy8nL5fL64EQwGk30aAEAGSMmH2j311FP629/+Fnvcs2fPVJwGAJDmUhJCjz32GKsfAMB9peQ5oTNnzig/P19FRUWaN2+ezp07d89jo9GoIpFI3AAAdA9JD6GxY8dq27Zt2r9/v95++201NTVpwoQJamlp6fD4iooKBQKB2CgoKEh2SwCALirl7xNqa2vTk08+qZUrV6qsrKzd/mg0qmg0GnsciUQIImQ83id0G+8TymwP8j6hlDwn9GX9+vXTsGHDdObMmQ73+/1++f3+VLcBAOiCUv4+oWg0qs8++0yhUCjVpwIApJmkh9Brr72m2tpa1dfX65///Ke+/e1vKxKJqLS0NNmnAgCkuaT/Ou7zzz/X/PnzdenSJQ0YMEDjxo3TkSNHVFhYmOxTAQDSHDcwBR7SM88847nm3Xff9VyTn5/vuSbR/96tra2ea65fv+65JpEXGUycONFzzbFjxzzXSIl9Tfh/3MAUANClEUIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMJPyD7UDLPTt2zehupEjR3queeeddzzXdPXP17rXh1B2Zv369Z5rdu7c6bnmH//4h+eaNWvWeK6RpIqKioTq8OBYCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzHAXbWSk3/zmNwnVzZ8/P8mdpKdE7ib+xBNPeK6pra31XDNlyhTPNU8//bTnGjwarIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY4Qam6PJGjRrlueZb3/pWQufy+XwJ1XmVyI07//KXv3iuefPNNz3XSNLFixc91xw/ftxzzeXLlz3XTJs2zXPNo/p3hXeshAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJjxOeecdRNfFolEFAgErNtAiowYMcJzTXV1teea7OxszzWJ+utf/+q5Zv78+Z5rJk+e7Lnm6aef9lwjSb/73e881/z3v/9N6Fxe3bx503PN1atXEzpXItf82LFjCZ0rE4XD4fv+X2QlBAAwQwgBAMx4DqGDBw9q5syZys/Pl8/n0549e+L2O+dUXl6u/Px89enTR1OmTNGpU6eS1S8AIIN4DqG2tjYNHz5clZWVHe5fv369Nm7cqMrKStXV1SkYDGr69OlqbW196GYBAJnF8yerlpSUqKSkpMN9zjm99dZbWr16tebMmSNJ2rp1q/Ly8rRjxw4tXrz44boFAGSUpD4nVF9fr6amJhUXF8e2+f1+TZ48WYcPH+6wJhqNKhKJxA0AQPeQ1BBqamqSJOXl5cVtz8vLi+27W0VFhQKBQGwUFBQksyUAQBeWklfH+Xy+uMfOuXbb7li1apXC4XBsNDQ0pKIlAEAX5Pk5oc4Eg0FJt1dEoVAotr25ubnd6ugOv98vv9+fzDYAAGkiqSuhoqIiBYNBVVVVxbZdv35dtbW1mjBhQjJPBQDIAJ5XQleuXNHZs2djj+vr63XixAnl5ORo0KBBWrFihdatW6fBgwdr8ODBWrdunfr27asXX3wxqY0DANKf5xD65JNPNHXq1NjjsrIySVJpaan++Mc/auXKlbp27ZqWLFmiy5cva+zYsfroo4+UlZWVvK4BABmBG5giYUOGDPFcs3btWs818+bN81xz6dIlzzWS1NjY6LnmZz/7meeaP//5z55rcFsiNzBN9Nvcrl27PNd897vfTehcmYgbmAIAujRCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJmkfrIq0lOin2z75ptveq755je/6bmmtbXVc82CBQs810i3P6rEqz59+iR0LnR9gwYNsm4h47ESAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYbmELf+MY3EqpL5GakiZg1a5bnmtra2hR0AiDZWAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwww1MoY0bNyZU5/P5PNckcmNRbkaKL+vRw/vPzrdu3UpBJ0gGVkIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMcAPTDPPcc895rhkxYkRC53LOea7Zu3dvQucC7kjkZqSJzFVJOnHiREJ1eHCshAAAZgghAIAZzyF08OBBzZw5U/n5+fL5fNqzZ0/c/oULF8rn88WNcePGJatfAEAG8RxCbW1tGj58uCorK+95zIwZM9TY2Bgb+/bte6gmAQCZyfMLE0pKSlRSUtLpMX6/X8FgMOGmAADdQ0qeE6qpqVFubq6GDBmiRYsWqbm5+Z7HRqNRRSKRuAEA6B6SHkIlJSXavn27qqurtWHDBtXV1WnatGmKRqMdHl9RUaFAIBAbBQUFyW4JANBFJf19QnPnzo39eejQoRo9erQKCwv1wQcfaM6cOe2OX7VqlcrKymKPI5EIQQQA3UTK36waCoVUWFioM2fOdLjf7/fL7/enug0AQBeU8vcJtbS0qKGhQaFQKNWnAgCkGc8roStXrujs2bOxx/X19Tpx4oRycnKUk5Oj8vJyvfDCCwqFQjp//rx+9KMfqX///nr++eeT2jgAIP15DqFPPvlEU6dOjT2+83xOaWmpNm/erJMnT2rbtm363//+p1AopKlTp2rXrl3KyspKXtcAgIzgOYSmTJnS6c0A9+/f/1AN4eH06dPHc03v3r0TOldnL72/l127diV0LnR9iTy3W15envxGOlBdXZ1Q3apVq5LcCe7GveMAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGZS/smqyFzRaNRzTWNjYwo6QbIlckfsNWvWeK75wQ9+4Lnm888/91yzYcMGzzXS7c9PQ2qxEgIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGG5giYXv37rVuAfcxYsSIhOoSubHo3LlzPde8//77nmteeOEFzzXoulgJAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMMMNTDOMz+d7JDWSNHv2bM81r7zySkLngvT973/fc83rr7+e0LkCgYDnmu3bt3uuWbBggecaZBZWQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMxwA9MM45x7JDWSFAwGPdf84he/8Fzzhz/8wXNNS0uL5xpJGjdunOeal156yXPN8OHDPdcMHDjQc82FCxc810jS/v37Pdds2rQpoXOhe2MlBAAwQwgBAMx4CqGKigqNGTNGWVlZys3N1ezZs3X69Om4Y5xzKi8vV35+vvr06aMpU6bo1KlTSW0aAJAZPIVQbW2tli5dqiNHjqiqqko3btxQcXGx2traYsesX79eGzduVGVlperq6hQMBjV9+nS1trYmvXkAQHrz9MKEDz/8MO7xli1blJubq6NHj2rSpElyzumtt97S6tWrNWfOHEnS1q1blZeXpx07dmjx4sXJ6xwAkPYe6jmhcDgsScrJyZEk1dfXq6mpScXFxbFj/H6/Jk+erMOHD3f4d0SjUUUikbgBAOgeEg4h55zKyso0ceJEDR06VJLU1NQkScrLy4s7Ni8vL7bvbhUVFQoEArFRUFCQaEsAgDSTcAgtW7ZMn376qf70pz+12+fz+eIeO+fabbtj1apVCofDsdHQ0JBoSwCANJPQm1WXL1+uvXv36uDBg3FvoLvz5sWmpiaFQqHY9ubm5narozv8fr/8fn8ibQAA0pynlZBzTsuWLdPu3btVXV2toqKiuP1FRUUKBoOqqqqKbbt+/bpqa2s1YcKE5HQMAMgYnlZCS5cu1Y4dO/T+++8rKysr9jxPIBBQnz595PP5tGLFCq1bt06DBw/W4MGDtW7dOvXt21cvvvhiSr4AAED68hRCmzdvliRNmTIlbvuWLVu0cOFCSdLKlSt17do1LVmyRJcvX9bYsWP10UcfKSsrKykNAwAyh88levfKFIlEIgoEAtZtpK3vfOc7nms6enFJV/Kf//zHc02iL/UfPHhwQnWPwscff+y55sCBAwmd68c//nFCdcCXhcNhZWdnd3oM944DAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJhJ6JNV0XUlcqflurq6hM41ZsyYhOq8uvOJvV7c65N8U6GlpcVzzc6dOz3XvPLKK55rgK6OlRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzPuecs27iyyKRiAKBgHUb3UooFEqobvHixZ5r1qxZ47nG5/N5rkl0Wv/85z/3XLN582bPNWfPnvVcA6SbcDis7OzsTo9hJQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMNzAFAKQENzAFAHRphBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAw4ymEKioqNGbMGGVlZSk3N1ezZ8/W6dOn445ZuHChfD5f3Bg3blxSmwYAZAZPIVRbW6ulS5fqyJEjqqqq0o0bN1RcXKy2tra442bMmKHGxsbY2LdvX1KbBgBkhse8HPzhhx/GPd6yZYtyc3N19OhRTZo0Kbbd7/crGAwmp0MAQMZ6qOeEwuGwJCknJydue01NjXJzczVkyBAtWrRIzc3N9/w7otGoIpFI3AAAdA8+55xLpNA5p1mzZuny5cs6dOhQbPuuXbv0xBNPqLCwUPX19Xr99dd148YNHT16VH6/v93fU15erp/85CeJfwUAgC4pHA4rOzu784NcgpYsWeIKCwtdQ0NDp8ddvHjR9erVy7377rsd7v/iiy9cOByOjYaGBieJwWAwGGk+wuHwfbPE03NCdyxfvlx79+7VwYMHNXDgwE6PDYVCKiws1JkzZzrc7/f7O1whAQAyn6cQcs5p+fLleu+991RTU6OioqL71rS0tKihoUGhUCjhJgEAmcnTCxOWLl2qd955Rzt27FBWVpaamprU1NSka9euSZKuXLmi1157TR9//LHOnz+vmpoazZw5U/3799fzzz+fki8AAJDGvDwPpHv83m/Lli3OOeeuXr3qiouL3YABA1yvXr3coEGDXGlpqbtw4cIDnyMcDpv/HpPBYDAYDz8e5DmhhF8dlyqRSESBQMC6DQDAQ3qQV8dx7zgAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJkuF0LOOesWAABJ8CDfz7tcCLW2tlq3AABIggf5fu5zXWzpcevWLV28eFFZWVny+Xxx+yKRiAoKCtTQ0KDs7GyjDu1xHW7jOtzGdbiN63BbV7gOzjm1trYqPz9fPXp0vtZ57BH19MB69OihgQMHdnpMdnZ2t55kd3AdbuM63MZ1uI3rcJv1dQgEAg90XJf7dRwAoPsghAAAZtIqhPx+v9auXSu/32/diimuw21ch9u4DrdxHW5Lt+vQ5V6YAADoPtJqJQQAyCyEEADADCEEADBDCAEAzKRVCG3atElFRUV6/PHHNWrUKB06dMi6pUeqvLxcPp8vbgSDQeu2Uu7gwYOaOXOm8vPz5fP5tGfPnrj9zjmVl5crPz9fffr00ZQpU3Tq1CmbZlPoftdh4cKF7ebHuHHjbJpNkYqKCo0ZM0ZZWVnKzc3V7Nmzdfr06bhjusN8eJDrkC7zIW1CaNeuXVqxYoVWr16t48eP69lnn1VJSYkuXLhg3doj9dRTT6mxsTE2Tp48ad1SyrW1tWn48OGqrKzscP/69eu1ceNGVVZWqq6uTsFgUNOnT8+4+xDe7zpI0owZM+Lmx759+x5hh6lXW1urpUuX6siRI6qqqtKNGzdUXFystra22DHdYT48yHWQ0mQ+uDTxzDPPuJdffjlu29e+9jX3wx/+0KijR2/t2rVu+PDh1m2YkuTee++92ONbt265YDDo3njjjdi2L774wgUCAffrX//aoMNH4+7r4JxzpaWlbtasWSb9WGlubnaSXG1trXOu+86Hu6+Dc+kzH9JiJXT9+nUdPXpUxcXFcduLi4t1+PBho65snDlzRvn5+SoqKtK8efN07tw565ZM1dfXq6mpKW5u+P1+TZ48udvNDUmqqalRbm6uhgwZokWLFqm5udm6pZQKh8OSpJycHEnddz7cfR3uSIf5kBYhdOnSJd28eVN5eXlx2/Py8tTU1GTU1aM3duxYbdu2Tfv379fbb7+tpqYmTZgwQS0tLdatmbnz79/d54YklZSUaPv27aqurtaGDRtUV1enadOmKRqNWreWEs45lZWVaeLEiRo6dKik7jkfOroOUvrMhy53F+3O3P3RDs65dtsyWUlJSezPw4YN0/jx4/Xkk09q69atKisrM+zMXnefG5I0d+7c2J+HDh2q0aNHq7CwUB988IHmzJlj2FlqLFu2TJ9++qn+/ve/t9vXnebDva5DusyHtFgJ9e/fXz179mz3k0xzc3O7n3i6k379+mnYsGE6c+aMdStm7rw6kLnRXigUUmFhYUbOj+XLl2vv3r06cOBA3Ee/dLf5cK/r0JGuOh/SIoR69+6tUaNGqaqqKm57VVWVJkyYYNSVvWg0qs8++0yhUMi6FTNFRUUKBoNxc+P69euqra3t1nNDklpaWtTQ0JBR88M5p2XLlmn37t2qrq5WUVFR3P7uMh/udx060mXng+GLIjzZuXOn69Wrl/v973/v/vWvf7kVK1a4fv36ufPnz1u39si8+uqrrqamxp07d84dOXLEPffccy4rKyvjr0Fra6s7fvy4O378uJPkNm7c6I4fP+7+/e9/O+ece+ONN1wgEHC7d+92J0+edPPnz3ehUMhFIhHjzpOrs+vQ2trqXn31VXf48GFXX1/vDhw44MaPH++++tWvZtR1+N73vucCgYCrqalxjY2NsXH16tXYMd1hPtzvOqTTfEibEHLOuV/96leusLDQ9e7d240cOTLu5Yjdwdy5c10oFHK9evVy+fn5bs6cOe7UqVPWbaXcgQMHnKR2o7S01Dl3+2W5a9eudcFg0Pn9fjdp0iR38uRJ26ZToLPrcPXqVVdcXOwGDBjgevXq5QYNGuRKS0vdhQsXrNtOqo6+fkluy5YtsWO6w3y433VIp/nARzkAAMykxXNCAIDMRAgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwMz/AdDDJYtBgQkJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((mnist_28_img[1].reshape(28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mnist_28.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        0\n",
       "2        4\n",
       "3        1\n",
       "4        9\n",
       "        ..\n",
       "69995    2\n",
       "69996    3\n",
       "69997    4\n",
       "69998    5\n",
       "69999    6\n",
       "Name: class, Length: 70000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEKHYA\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((56000, 784), (14000, 784), (56000, 10), (14000, 10))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = mnist_28_img / 255.0\n",
    "y = np.array(y.astype(int)) \n",
    "\n",
    "#Converting labels to one-hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = y.reshape(-1, 1)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "#Splitting the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU (Rectified Linear Unit) activation function.\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    \"\"\"Derivative of the ReLU (Rectified Linear Unit) activation function.\"\"\"\n",
    "    return (x > 0).astype(x.dtype)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Softmax activation function.\"\"\"\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    \"\"\"Initialize parameters for a neural network.\"\"\"\n",
    "    np.random.seed(42)  #For reproducibility\n",
    "    Wh = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)  # Initialize weights for hidden layer\n",
    "    bh = np.zeros((1, hidden_size))                                           # Initialize bias for hidden layer\n",
    "    Wo = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)# Initialize weights for output layer\n",
    "    bo = np.zeros((1, output_size))                                           # Initialize bias for output layer\n",
    "    return Wh, bh, Wo, bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, Wh, bh, Wo, bo):\n",
    "    \"\"\"Perform forward pass through a neural network.\"\"\"\n",
    "    # Hidden layer\n",
    "    inputHidden = np.dot(X, Wh) + bh                     # Calculate input to hidden layer\n",
    "    outputHidden = relu(inputHidden)                     # Apply ReLU activation to hidden layer output\n",
    "    # Output layer\n",
    "    inputForOutputLayer = np.dot(outputHidden, Wo) + bo  # Calculate input to output layer\n",
    "    output = softmax(inputForOutputLayer)                 # Apply softmax activation to output layer\n",
    "    return inputHidden, outputHidden, inputForOutputLayer, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(Y, Y_hat):\n",
    "    \"\"\"Compute the cross-entropy loss.\"\"\"\n",
    "    m = Y.shape[0]                                                          # Number of samples\n",
    "    return -np.mean(np.log(Y_hat[np.arange(m), Y.argmax(axis=1)] + 1e-9))    # Calculate cross-entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(X, Y, inputHidden, outputHidden, inputForOutputLayer, output, Wh, bh, Wo, bo):\n",
    "    \"\"\"Perform backpropagation to compute gradients.\"\"\"\n",
    "    m = Y.shape[0]\n",
    "    # Output layer error\n",
    "    error_output_layer = output - Y                                                  # Calculate error at output layer\n",
    "    changes_output = np.dot(outputHidden.T, error_output_layer) / m                  # Compute gradients for weights in output layer\n",
    "    changes_output_bias = np.sum(error_output_layer, axis=0, keepdims=True) / m      # Compute gradients for biases in output layer\n",
    "    # Hidden layer error\n",
    "    error_hidden_layer = np.dot(error_output_layer, Wo.T) * relu_deriv(inputHidden)  # Calculate error at hidden layer\n",
    "    changes_hidden = np.dot(X.T, error_hidden_layer) / m                             # Compute gradients for weights in hidden layer\n",
    "    changes_hidden_bias = np.sum(error_hidden_layer, axis=0, keepdims=True) / m      # Compute gradients for biases in hidden layer\n",
    "    \n",
    "    return changes_hidden, changes_hidden_bias, changes_output, changes_output_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(Wh, bh, Wo, bo, changes_hidden, changes_hidden_bias, changes_output, changes_output_bias, learning_rate):\n",
    "    \"\"\"Update parameters using gradient descent.\"\"\"\n",
    "    # Update weights and biases in hidden layer\n",
    "    Wh -= learning_rate * changes_hidden\n",
    "    bh -= learning_rate * changes_hidden_bias\n",
    "    # Update weights and biases in output layer\n",
    "    Wo -= learning_rate * changes_output\n",
    "    bo -= learning_rate * changes_output_bias\n",
    "    return Wh, bh, Wo, bo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, Y_train, X_test, Y_test, hidden_size, learning_rate, epochs):\n",
    "    \"\"\"Train the neural network model.\"\"\"\n",
    "    input_size, output_size = X_train.shape[1], Y_train.shape[1]                  # Get input and output sizes\n",
    "    \n",
    "    # Initialize parameters\n",
    "    Wh, bh, Wo, bo = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "     # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        inputHidden, outputHidden, inputForOutputLayer, output = forward_pass(X_train, Wh, bh, Wo, bo)\n",
    "        # Compute loss\n",
    "        loss = compute_loss(Y_train, output)\n",
    "        # Backpropagation\n",
    "        changes_hidden, changes_hidden_bias, changes_output, changes_output_bias = backprop(X_train, Y_train, inputHidden, outputHidden, inputForOutputLayer, output, Wh, bh, Wo, bo)\n",
    "        # Update parameters\n",
    "        Wh, bh, Wo, bo = update_parameters(Wh, bh, Wo, bo, changes_hidden, changes_hidden_bias, changes_output, changes_output_bias, learning_rate)\n",
    "        \n",
    "        # Print loss every 5 epochs\n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}, loss: {loss}\")\n",
    "            \n",
    "    # Evaluation\n",
    "    _, _, _, A2_train = forward_pass(X_train, Wh, bh, Wo, bo)\n",
    "    train_accuracy = np.mean(np.argmax(A2_train, axis=1) == np.argmax(Y_train, axis=1))\n",
    "    print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    _, _, _, A2_test = forward_pass(X_test, Wh, bh, Wo, bo)\n",
    "    test_accuracy = np.mean(np.argmax(A2_test, axis=1) == np.argmax(Y_test, axis=1))\n",
    "    print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.4696983843981926\n",
      "Epoch 5, loss: 1.8659091303471023\n",
      "Epoch 10, loss: 1.4840461864920003\n",
      "Epoch 15, loss: 1.2101790493611508\n",
      "Epoch 20, loss: 1.0227734130045845\n",
      "Epoch 25, loss: 0.8938405372763555\n",
      "Epoch 30, loss: 0.8019055824967123\n",
      "Epoch 35, loss: 0.7337266502374247\n",
      "Epoch 40, loss: 0.6812886236015083\n",
      "Epoch 45, loss: 0.6397244557690626\n",
      "Epoch 49, loss: 0.6121932524302102\n",
      "Training accuracy: 85.63%\n",
      "Test accuracy: 85.86%\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "train(X_train, y_train, X_test, y_test, hidden_size, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d44fdebdd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((X_test[0].reshape(28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALEKHYA\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Splitting the dataset into training and testing labels\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    \"\"\"Initialize the convolutional layer.\"\"\"\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters            # Number of filters\n",
    "        self.filter_size = filter_size             # Size of each filter\n",
    "        # Initialize filters with random values\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size * filter_size)\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"Iterate over all possible regions of the input image.\"\"\"\n",
    "        h, w = image.shape                       # Height and width of the input image\n",
    "\n",
    "        for i in range(h - self.filter_size + 1):\n",
    "            for j in range(w - self.filter_size + 1):\n",
    "                region = image[i:(i + self.filter_size), j:(j + self.filter_size)]  # Extract region of interest\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Perform forward pass through the convolutional layer.\"\"\"\n",
    "        self.last_input = input              # Save input for backpropagation\n",
    "        h, w = input.shape                   # Height and width of the input\n",
    "        \n",
    "        # Initialize output array\n",
    "        output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n",
    "        # Iterate over each region of the input\n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            # Perform convolution and sum the results\n",
    "            output[i, j] = np.sum(region * self.filters, axis=(1, 2))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \"\"\"Perform backpropagation through the convolutional layer.\"\"\"\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "\n",
    "        for region, i, j in self.iterate_regions(self.last_input):\n",
    "            # Update gradients for each filter\n",
    "            for f in range(self.num_filters):\n",
    "                d_L_d_filters[f] += d_L_d_out[i, j, f] * region\n",
    "        \n",
    "        # Update filters using the gradients\n",
    "        self.filters -= learn_rate * d_L_d_filters\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    def iterate_regions(self, image):\n",
    "        # Define the generator to iterate over regions of the input image\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h // 2\n",
    "        new_w = w // 2\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                # Extract the region of interest\n",
    "                region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Perform forward pass through the max-pooling layer\n",
    "        self.last_input = input\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // 2, w // 2, num_filters))\n",
    "\n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            # Find the maximum value in each region and store it in the output\n",
    "            output[i, j] = np.amax(region, axis=(0, 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backprop(self, d_L_d_out):\n",
    "        # Perform backpropagation through the max-pooling layer\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for region, i, j in self.iterate_regions(self.last_input):\n",
    "            # Find the maximum value in each region\n",
    "            h, w, f = region.shape\n",
    "            amax = np.amax(region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        # Assign the gradient to the corresponding input value\n",
    "                        if region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "        return d_L_d_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self, input_len, nodes):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Perform forward pass through the softmax layer\n",
    "        self.last_input_shape = input.shape\n",
    "        input = input.flatten()            # Flatten input\n",
    "        self.last_input = input\n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        # Calculate scores\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        self.last_totals = totals\n",
    "\n",
    "        # Calculate probabilities using softmax function\n",
    "        exp = np.exp(totals)\n",
    "        return exp / np.sum(exp, axis=0)\n",
    "\n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        # Perform backpropagation through the softmax layer\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            t_exp = np.exp(self.last_totals)\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            # Calculate derivative of softmax function\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "            # Compute gradients\n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "            # Update weights and biases using gradients\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.biases -= learn_rate * d_L_d_b\n",
    "\n",
    "            # Reshape gradients to match input shape\n",
    "            return d_L_d_inputs.reshape(self.last_input_shape)\n",
    "\n",
    "conv = Convolution(8, 3)        # Initialize convolutional layer with 8 filters of size 3x3\n",
    "pool = MaxPool()                # Initialize max pooling layer\n",
    "softmax = Softmax(13 * 13 * 8, 10)  # Initialize softmax layer with input size 13x13x8 and output size 10\n",
    "\n",
    "\n",
    "def forward(image, label):\n",
    "    # Perform forward pass through the neural network\n",
    "    out = conv.forward((image / 255) - 0.5)        # Normalize image and pass through convolutional layer\n",
    "    out = pool.forward(out)                        # Pass through max pooling layer\n",
    "    out = softmax.forward(out)                     # Pass through softmax layer\n",
    "\n",
    "    # Compute loss and accuracy\n",
    "    loss = -np.log(out[label])\n",
    "    acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "    return out, loss, acc\n",
    "\n",
    "def train(image, label, learn_rate=0.005):\n",
    "    # Perform training for a single image-label pair\n",
    "    out, loss, acc = forward(image, label)           # Forward pass\n",
    "\n",
    "    # Compute gradient for softmax layer\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1 / out[label]\n",
    "\n",
    "    grad_back = softmax.backprop(gradient, learn_rate)   # Backpropagate through softmax layer\n",
    "    grad_back = pool.backprop(grad_back)                 # Backpropagate through max pooling layer\n",
    "    grad_back = conv.backprop(grad_back, learn_rate)     # Backpropagate through convolutional layer\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Step: 10000, Average_loss: 0.47701, Accuracy: 84.88%\n",
      "Step: 20000, Average_loss: 0.38155, Accuracy: 88.15%\n",
      "Step: 30000, Average_loss: 0.33288, Accuracy: 89.77%\n",
      "Step: 40000, Average_loss: 0.30575, Accuracy: 90.67%\n",
      "Step: 50000, Average_loss: 0.28448, Accuracy: 91.38%\n",
      "Final Epoch Metrics - Average_loss: 0.26720, Accuracy: 91.91%\n",
      "Test loss: 0.17184600461953162\n",
      "Test Accuracy: 94.83 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    print('Epoch:', epoch + 1)\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_data = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[shuffle_data]\n",
    "    train_labels = train_labels[shuffle_data]\n",
    "\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i % 10000 == 0 and i > 0:  # Change to 10000 for less frequent logging\n",
    "            print(f\"Step: {i}, Average_loss: {loss / i:.5f}, Accuracy: {num_correct / i * 100:.2f}%\")\n",
    "            # Resetting loss and num_correct after logging is removed to calculate cumulative metrics\n",
    "\n",
    "        # Perform training for a single image-label pair\n",
    "        l1, accu = train(im, label)\n",
    "        loss += l1\n",
    "        num_correct += accu\n",
    "\n",
    "    # Print final epoch metrics\n",
    "    print(f\"Final Epoch Metrics - Average_loss: {loss / len(train_images):.5f}, Accuracy: {num_correct / len(train_images) * 100:.2f}%\")\n",
    "\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "\n",
    "# Evaluate on test data\n",
    "for im, label in zip(test_images, test_labels):\n",
    "    _, l1, accu = forward(im, label)\n",
    "    test_loss += l1\n",
    "    test_correct += accu\n",
    "\n",
    "print('Test loss:', test_loss / len(test_images))\n",
    "print('Test Accuracy:', test_correct / len(test_images) * 100, '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Network provided a accuracy and loss of **85.86%** and **0.61** for 50 epochs respectively,\n",
    "\n",
    "Convolution Neural Network provided a validation accuracy and loss score of **94.83%** and **0.17** for 5 steps in 1 epoch respectively."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgsit5VP94HjlMskC8S520",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
